{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927a1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880f667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ab7dc",
   "metadata": {},
   "source": [
    "## Creamos una Sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f589ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"miPrimeraSession\") \\\n",
    "        .getOrCreate()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed904df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfdf8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = SparkContext(master=\"local\", appName=\"miPrimerContext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cc30010",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94062663",
   "metadata": {},
   "source": [
    "## Creamos un DataFrame con numeros del 1 al 50000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2638cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRange = spark.range(50000000).toDF(\"numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded36a5d",
   "metadata": {},
   "source": [
    "#### Creamos un nuevo DataFrame a partir del dataframe anterior en donde los numeros sean pares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e1dcdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "divBy2 = myRange.where(\"numbers % 2 == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "909ec98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      0|\n",
      "|      2|\n",
      "|      4|\n",
      "|      6|\n",
      "|      8|\n",
      "|     10|\n",
      "|     12|\n",
      "|     14|\n",
      "|     16|\n",
      "|     18|\n",
      "|     20|\n",
      "|     22|\n",
      "|     24|\n",
      "|     26|\n",
      "|     28|\n",
      "|     30|\n",
      "|     32|\n",
      "|     34|\n",
      "|     36|\n",
      "|     38|\n",
      "|     40|\n",
      "|     42|\n",
      "|     44|\n",
      "|     46|\n",
      "|     48|\n",
      "|     50|\n",
      "|     52|\n",
      "|     54|\n",
      "|     56|\n",
      "|     58|\n",
      "|     60|\n",
      "|     62|\n",
      "|     64|\n",
      "|     66|\n",
      "|     68|\n",
      "|     70|\n",
      "|     72|\n",
      "|     74|\n",
      "|     76|\n",
      "|     78|\n",
      "|     80|\n",
      "|     82|\n",
      "|     84|\n",
      "|     86|\n",
      "|     88|\n",
      "|     90|\n",
      "|     92|\n",
      "|     94|\n",
      "|     96|\n",
      "|     98|\n",
      "|    100|\n",
      "|    102|\n",
      "|    104|\n",
      "|    106|\n",
      "|    108|\n",
      "|    110|\n",
      "|    112|\n",
      "|    114|\n",
      "|    116|\n",
      "|    118|\n",
      "|    120|\n",
      "|    122|\n",
      "|    124|\n",
      "|    126|\n",
      "|    128|\n",
      "|    130|\n",
      "|    132|\n",
      "|    134|\n",
      "|    136|\n",
      "|    138|\n",
      "|    140|\n",
      "|    142|\n",
      "|    144|\n",
      "|    146|\n",
      "|    148|\n",
      "|    150|\n",
      "|    152|\n",
      "|    154|\n",
      "|    156|\n",
      "|    158|\n",
      "|    160|\n",
      "|    162|\n",
      "|    164|\n",
      "|    166|\n",
      "|    168|\n",
      "|    170|\n",
      "|    172|\n",
      "|    174|\n",
      "|    176|\n",
      "|    178|\n",
      "|    180|\n",
      "|    182|\n",
      "|    184|\n",
      "|    186|\n",
      "|    188|\n",
      "|    190|\n",
      "|    192|\n",
      "|    194|\n",
      "|    196|\n",
      "|    198|\n",
      "+-------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divBy2.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a17ff7",
   "metadata": {},
   "source": [
    "### leemos un archivo csv \n",
    "inferSchema se refiere a deducir el tipo de datos que almacena este archivo\n",
    "header es para indicarle a spark que la primera fila contiene los nombres de las columnas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d228cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015 = spark \\\n",
    "                .read \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"../data/flight-data/csv/2015-summary.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e02251",
   "metadata": {},
   "source": [
    "## Ordenamos los datos por la columna count\n",
    "para ordenarlos de forma descendete se agrega el parametro ascending = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c354ef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='United States', count=370002),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Canada', count=8483),\n",
       " Row(DEST_COUNTRY_NAME='Canada', ORIGIN_COUNTRY_NAME='United States', count=8399),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Mexico', count=7187),\n",
       " Row(DEST_COUNTRY_NAME='Mexico', ORIGIN_COUNTRY_NAME='United States', count=7140),\n",
       " Row(DEST_COUNTRY_NAME='United Kingdom', ORIGIN_COUNTRY_NAME='United States', count=2025),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='United Kingdom', count=1970),\n",
       " Row(DEST_COUNTRY_NAME='Japan', ORIGIN_COUNTRY_NAME='United States', count=1548),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Japan', count=1496),\n",
       " Row(DEST_COUNTRY_NAME='Germany', ORIGIN_COUNTRY_NAME='United States', count=1468),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Dominican Republic', count=1420),\n",
       " Row(DEST_COUNTRY_NAME='Dominican Republic', ORIGIN_COUNTRY_NAME='United States', count=1353),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Germany', count=1336),\n",
       " Row(DEST_COUNTRY_NAME='South Korea', ORIGIN_COUNTRY_NAME='United States', count=1048),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='The Bahamas', count=986),\n",
       " Row(DEST_COUNTRY_NAME='The Bahamas', ORIGIN_COUNTRY_NAME='United States', count=955),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='France', count=952),\n",
       " Row(DEST_COUNTRY_NAME='France', ORIGIN_COUNTRY_NAME='United States', count=935),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='China', count=920),\n",
       " Row(DEST_COUNTRY_NAME='Colombia', ORIGIN_COUNTRY_NAME='United States', count=873)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.sort(\"count\", ascending=False).take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7abb9",
   "metadata": {},
   "source": [
    "# Importante\n",
    "Para establecer el numero de particiones que queremos que spark utilice, se ejecuta la siguiente linea de código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53e94d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5799d",
   "metadata": {},
   "source": [
    "Con spark se puede transformar un DataFrame a una tabla o una vista, la siguiente linea de código tansforma el DataFrame a una vista de base de datos, se puede relizar cualquier consulta con lenguaje SQL, por ejemplo \"SELECT * FROM nombre_tabla\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1e216c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf0a18c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+\n",
      "| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+------------------+-------------------+------+\n",
      "|     United States|      United States|370002|\n",
      "|     United States|             Canada|  8483|\n",
      "|            Canada|      United States|  8399|\n",
      "|     United States|             Mexico|  7187|\n",
      "|            Mexico|      United States|  7140|\n",
      "|    United Kingdom|      United States|  2025|\n",
      "|     United States|     United Kingdom|  1970|\n",
      "|             Japan|      United States|  1548|\n",
      "|     United States|              Japan|  1496|\n",
      "|           Germany|      United States|  1468|\n",
      "|     United States| Dominican Republic|  1420|\n",
      "|Dominican Republic|      United States|  1353|\n",
      "|     United States|            Germany|  1336|\n",
      "|       South Korea|      United States|  1048|\n",
      "+------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlWay = spark.sql(\"SELECT * FROM flight_data_2015 WHERE count >1000 ORDER BY count DESC\")\n",
    "sqlWay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd1015a",
   "metadata": {},
   "source": [
    "Spark es parecido a SQL y brinda las funciones para obtener el mismo resultado que la sentencia SQL anterior, en la siguiente linea de describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19b01c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+\n",
      "| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+------------------+-------------------+------+\n",
      "|     United States|      United States|370002|\n",
      "|     United States|             Canada|  8483|\n",
      "|            Canada|      United States|  8399|\n",
      "|     United States|             Mexico|  7187|\n",
      "|            Mexico|      United States|  7140|\n",
      "|    United Kingdom|      United States|  2025|\n",
      "|     United States|     United Kingdom|  1970|\n",
      "|             Japan|      United States|  1548|\n",
      "|     United States|              Japan|  1496|\n",
      "|           Germany|      United States|  1468|\n",
      "|     United States| Dominican Republic|  1420|\n",
      "|Dominican Republic|      United States|  1353|\n",
      "|     United States|            Germany|  1336|\n",
      "|       South Korea|      United States|  1048|\n",
      "+------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDfway = flightData2015.where(\"COUNT > 1000\").orderBy(\"count\",ascending=False)\n",
    "myDfway.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
